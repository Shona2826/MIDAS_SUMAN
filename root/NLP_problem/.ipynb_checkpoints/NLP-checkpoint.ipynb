{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('V1.4_Training.csv')\n",
    "data_test = pd.read_csv('SubtaskA_Trial_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID                                            COMMENT  LABEL\n",
      "0  663_3  \"Please enable removing language code from the...      1\n",
      "1  663_4  \"Note: in your .csproj file, there is a Suppor...      0\n",
      "2  664_1  \"Wich means the new version not fully replaced...      0\n",
      "3  664_2  \"Some of my users will still receive the old x...      0\n",
      "4  664_3  \"The store randomly gives the old xap or the n...      0\n",
      "      id                                            comment label\n",
      "0  13101  \"I'm not asking Microsoft to Gives permission ...     X\n",
      "1  13121            \"somewhere between Android and iPhone.\"     X\n",
      "2  13131  \"And in the Windows Store you can flag the App...     X\n",
      "3  13132  \"Many thanks Sameh Hi, As we know, there is a ...     X\n",
      "4  13133  \"The idea is that we can develop a regular app...     X\n"
     ]
    }
   ],
   "source": [
    "print(data_train.head())\n",
    "print(data_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = data_train.iloc[:, 1]\n",
    "\n",
    "train_x = []\n",
    "for line in train_dataframe:\n",
    "    train_x.append(line)\n",
    "\n",
    "\n",
    "train_label_dataframe = data_train.iloc[:, 2]\n",
    "train_y = []\n",
    "for line in train_label_dataframe:\n",
    "    train_y.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_dataframe = data_test.iloc[:, 1]\n",
    "for line in test_dataframe:\n",
    "    test_x.append(line)\n",
    "\n",
    "with open('labels.txt', 'r') as f:\n",
    "    test_y_file = f.readlines()\n",
    "\n",
    "test_y = []\n",
    "for val in test_y_file:\n",
    "    test_y.append(val[0])\n",
    "for index, val in enumerate(test_y):\n",
    "    val = int(val)\n",
    "    test_y[index] = val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data:  8500\n",
      "Size of test data:   592\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train data: \", len(train_x))\n",
    "print(\"Size of test data:  \", len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing the text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    for index ,line in enumerate(data):\n",
    "        line = line.lower()\n",
    "        line = re.sub(r'\\d+', '', line)\n",
    "        translation = str.maketrans(\" \",\" \", string.punctuation);\n",
    "        line = line.translate(string.punctuation)\n",
    "        line = line.translate(translation);\n",
    "        data[index] = line\n",
    "        \n",
    "preprocess(train_x)\n",
    "preprocess(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the same happened with facebook integration\n",
      "these descriptions also appear differently depending on where they are being viewed web zune on pc or device\n"
     ]
    }
   ],
   "source": [
    "print(train_x[100])\n",
    "print(test_x[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating the nlp model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import several things from Keras.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Neural Network cannot work directly on text-strings dataset so there is a step called tokenizer which converts words to integer and is done on the dataset before it is given as input to the Neural Network</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = 5000\n",
    "tokenizer = Tokenizer(num_words = vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fitting the tokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = train_x + test_x\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "train_x_tokens = tokenizer.texts_to_sequences(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the same happened with facebook integration'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   91, 1338,   16,  361,  447])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x_tokens[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Need to convert the texts in the test-set to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tokens = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'somewhere between android and iphone'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1224,  226,  147,    4,  640])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data,it need to have the same length so either ensure that all in the entire data-set have the same length, or write a custom data-generator that ensures that it has the same length within each batch.<br>\n",
    "First is simpler but if the length of the longest sequence in the data-set is used, then a lot of memory is wated which is a problem in large dataset.<br>So sequence-length is used that covers most sequences in the data-set, and then truncate longer sequences and pad shorter sequences.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in train_x_tokens + test_x_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.828090629124507"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The max number of token set to the average plus 2.5 times standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens)+ 2.5 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "print(max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its imp to decide whether to do padding or truncating pre or post. Truncation means part of the sequence thrown away and padding means adding zeros at the front or at the end here pre is used bcoz it is set that model will know the text is starting and if post is done then there is a chance of forgetting as so many zeros will come.<br>But when truncating  is used it  may loose some important information or features then we have to make compromise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,   46, ...,   43,    6,  472],\n",
       "       [   0,    0,    0, ..., 1534,    4, 2733],\n",
       "       [   0,    0,    0, ...,   97, 1028,  557],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1757,    2,   39],\n",
       "       [   0,    0,    0, ...,    3,  169,  633],\n",
       "       [   0,    0,    0, ...,    8,  207,  148]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 'pre'\n",
    "train_x_pad = pad_sequences(train_x_tokens, maxlen = max_tokens, padding= pad, truncating = pad)\n",
    "train_x_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_pad = pad_sequences(test_x_tokens, maxlen=max_tokens , padding = pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenizer inverse map</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defining a function for converting a list of tokens back to a string of words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    #Concatenate all the words\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Matching with the training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'note in your csproj file there is a supportedcultures entry like this supportedculturesdederururu supportedcultures when i removed the ru language code and published my new xap version the old xap version still remains in the store with replaced and unpublished'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'note in your csproj file there is a supportedcultures entry like this supportedcultures when i removed the ru language code and published my new xap version the old xap version still remains in the store with replaced and unpublished'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(train_x_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation of LSTM model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is the embedding layer which converts each integer-token into a vector of values<br><br>Each integer token will be converted to a vector of length (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer also need the number of words in the vocabulary and the length of the padded token sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim = num_words, output_dim = embedding_size\n",
    "                    , input_length = max_tokens, name = 'layer_embedding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an output of dimensionality 16 is produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(16, return_sequences = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds the second LSTM with 8 output units. This will be followed by another LSTM so it must also return sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(8, return_sequences = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds the third and final LSTM with 4 output units. This will be followed by a dense-layer, so it should only give the final output of the LSTM and not a whole sequence of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a fully-connected dense layer which computes a value between 0.0 and 1.0 that will be used as the classification output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compilation part</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>By using Adam optimizer and specifying the learning rate compiling the model. As it is a classification problem so using a cross entropy loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 45, 5)             25000     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 45, 16)            1408      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 45, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 27,421\n",
      "Trainable params: 27,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss ='binary_crossentropy', optimizer =  optimizer, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8075 samples, validate on 425 samples\n",
      "Epoch 1/5\n",
      "8075/8075 [==============================] - 8s 1ms/step - loss: 0.5938 - acc: 0.7402 - val_loss: 0.3224 - val_acc: 0.9741\n",
      "Epoch 2/5\n",
      "8075/8075 [==============================] - 6s 721us/step - loss: 0.5083 - acc: 0.7666 - val_loss: 0.3678 - val_acc: 0.8494\n",
      "Epoch 3/5\n",
      "8075/8075 [==============================] - 8s 963us/step - loss: 0.3621 - acc: 0.8625 - val_loss: 0.1906 - val_acc: 0.9318\n",
      "Epoch 4/5\n",
      "8075/8075 [==============================] - 6s 795us/step - loss: 0.2939 - acc: 0.8955 - val_loss: 0.1879 - val_acc: 0.9271\n",
      "Epoch 5/5\n",
      "8075/8075 [==============================] - 7s 845us/step - loss: 0.2556 - acc: 0.9095 - val_loss: 0.1836 - val_acc: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf760bb1d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_pad, train_y, validation_split = 0.05, epochs =3 , batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating its classification accuracy on the test-set</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 0s 287us/step\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x_pad, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 78.38%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SubtaskA_EvaluationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data.iloc[:,1]\n",
    "text = []\n",
    "for t in data_text:\n",
    "    text.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = pad_sequences(tokens, maxlen = max_tokens, padding= pad, truncating = pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = model.predict(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, val in enumerate(final):\n",
    "    if val>0.5:\n",
    "        final[index] = 1\n",
    "    else:\n",
    "        final[index] = 0\n",
    "\n",
    "submission = data.iloc[:, [0,1]]\n",
    "output = pd.DataFrame(final)\n",
    "result = pd.concat([submission,output], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(r'suman_goel.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
